import streamlit as st
import pandas as pd
import plotly.express as px
import os
from PIL import Image as PILImage
import base64
import requests
import io
from io import BytesIO
import tempfile
import json
import textwrap
import zipfile
from translate import Translator
from pandasai import SmartDataframe
from pandasai.responses.streamlit_response import StreamlitResponse
from pandasai.engine import set_pd_engine
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from openai import OpenAI

from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image
from reportlab.lib.units import cm

set_pd_engine("pandas")

# OpenAI API Key

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
# openai.api_key = "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"

# ƒêƒÉng k√Ω font Be VietNam Pro
pdfmetrics.registerFont(TTFont('BeVietNamPro', r'Be_Vietnam_Pro/BeVietnamPro-Light.ttf'))

export_folder = os.path.join(os.getcwd(), "exports")

# Load data
file_path = 'data_dv.csv'  # Replace with your uploaded file path
data = pd.read_csv(file_path)

# Page configuration
st.set_page_config(page_title="ChatBot", layout="wide")

# T√πy ch·ªânh CSS ƒë·ªÉ ƒë·∫©y Markdown s√°t tr√™n c√πng
st.markdown(
    """
    <style>
        .block-container {
            padding-top: 2rem; /* Lo·∫°i b·ªè kho·∫£ng c√°ch ph√≠a tr√™n */
        }
        h1 {
            text-align: center;
            margin-top: 0;
            padding-top: 0;
        }
    </style>
    """,
    unsafe_allow_html=True
)
st.markdown("<h3 style='text-align: center;'>ChatBot</h3>", unsafe_allow_html=True)

translator = Translator(to_lang="en", from_lang="vi")

with st.container():
    col1, col2 = st.columns(2)
    with col1.container(border=True):
        os.environ["PANDASAI_API_KEY"] = "$2a$10$GEsfXrwFuOWndHnBgXcSkecd3RlY3ffzDyDk19gXMRue4Dr.oqz4m"

        sdf = SmartDataframe(data, config={"save_charts": True, "save_charts_path": export_folder, "verbose": True, "response_parser": StreamlitResponse, "custom_whitelisted_dependencies": ["to_numeric"]})

        user_input = st.chat_input("Ask me:")

        if user_input:
            with st.container(border=True):
                with st.chat_message("assistant"):

                    translated_text = translator.translate(user_input)

                    response = sdf.chat(translated_text)

                    if isinstance(response, pd.DataFrame):
                        # Display the DataFrame directly
                        st.write(f"Chatbot:")
                        st.write(response)
                    else:
                        # If the response is a string (e.g., some text or CSV), handle it accordingly
                        # For example, if it's a CSV-like string:
                        st.write(f"Chatbot: {response}")

    with col2.container(border=True):
        
        modelfile = f"""B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu v√† bi·ªÉu ƒë·ªì v·ªõi ch·ªß ƒë·ªÅ Tai n·∫°n giao th√¥ng ·ªü Vi·ªát Nam, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng th√¥ng tin dataset ·ªü ƒë√¢y {data}"""

        # User input
        img_file_buffer = st.file_uploader("Upload an image", type=["png", "jpg", "jpeg"], accept_multiple_files=True)
        user_input = st.chat_input("Ask me ><:")

        if user_input:
            st.write("Input")
            # Create PDF in memory
            # pdf_buffer = BytesIO()
            # c = canvas.Canvas(pdf_buffer, pagesize=letter)

            # Add the paragraph
            # c.setFont("BeVietNamPro", 12)

            # T·ªça ƒë·ªô b·∫Øt ƒë·∫ßu
            # x_position = 100  # V·ªã tr√≠ x c·ªë ƒë·ªãnh
            # y_position = 750  # V·ªã tr√≠ y b·∫Øt ƒë·∫ßu t·ª´ tr√™n xu·ªëng
            # max_width = 450  # Chi·ªÅu r·ªông t·ªëi ƒëa c·ªßa m·ªôt d√≤ng

            # T·∫°o m·ªôt ƒë·ªëi t∆∞·ª£ng TextObject ƒë·ªÉ ch√®n to√†n b·ªô ƒëo·∫°n vƒÉn m√† kh√¥ng c·∫ßn d√πng strip
            # text_object = c.beginText(x_position, y_position)
            # text_object.setFont("BeVietNamPro", 12)
            # text_object.setTextOrigin(x_position, y_position)

            introduce_dataset_input = """H√£y vi·∫øt m·ªôt b·∫£n b√°o c√°o gi·ªõi thi·ªáu s∆° l∆∞·ª£c v·ªÅ t·∫≠p d·ªØ li·ªáu tai n·∫°n giao th√¥ng ·ªü Vi·ªát Nam, m√¥ t·∫£ c√°c thu·ªôc t√≠nh c≈©ng nh∆∞ s·ª≠ d·ª•ng c√°c ph√©p to√°n th·ªëng k√™ ƒë∆°n gi·∫£n cho t·∫≠p d·ªØ li·ªáu"""

            result = client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": modelfile},
                                {"role": "user", "content": introduce_dataset_input}
                            ],
                            max_tokens=500
                        )
            response_text = result.choices[0].message.content
            st.write(response_text)


            ##################################
            # T·∫°o file PDF
            pdf_buffer = io.BytesIO()

            pdf = SimpleDocTemplate(pdf_buffer, pagesize=A4)
            styles = getSampleStyleSheet()
            
            # T√πy ch·ªânh c√°c style
            title_style = ParagraphStyle(
                'TitleStyle', fontName='BeVietNamPro', fontSize=18, alignment=1, spaceAfter=12
            )
            body_style = ParagraphStyle(
                'BodyStyle', fontName='BeVietNamPro', fontSize=12, leading=14, spaceAfter=10
            )
            custom_style = ParagraphStyle(
                'CustomStyle', parent=body_style, alignment=0, spaceAfter=10
            )
            
            # N·ªôi dung PDF
            content = []
            content.append(Paragraph('B√°o C√°o Tai N·∫°n Giao Th√¥ng', title_style))
            content.append(Spacer(1, 0.5 * cm))
            
            # L·∫∑p 3 l·∫ßn ƒë·ªÉ ch√®n vƒÉn b·∫£n v√† ·∫£nh
            paragraphs = response_text.split('\n')
            for para in paragraphs:
                if para.strip():
                    content.append(Paragraph(para.strip(), custom_style))
                    content.append(Spacer(1, 0.2 * cm))
            
            #################################


            # wrapped_text = textwrap.wrap(response_text, width=80)

            # for line in wrapped_text:
            #     if y_position < 100:  # N·∫øu h·∫øt trang
            #         c.showPage()
            #         text_object = c.beginText(x_position, 750)
            #         text_object.setFont("BeVietNamPro", 12)
            #         y_position = 750

            #     text_object.setTextOrigin(x_position, y_position)
            #     text_object.textLine(line)
            #     y_position -= 15  # Gi·∫£m y_position cho m·ªói d√≤ng

            # c.drawText(text_object)
            st.success("Introduction added to the PDF!")


        # Hi·ªÉn th·ªã h√¨nh ·∫£nh n·∫øu ng∆∞·ªùi d√πng t·∫£i l√™n
            for image in img_file_buffer:
                if image:
                    image = PILImage.open(image)
                    # st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", width=500)
                    # image = image.resize((512, 200))
                    # image = image.convert("L")

                    buffered = io.BytesIO()
                    image.save(buffered, format="PNG")
                    img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

                    # X·ª≠ l√Ω h√¨nh ·∫£nh v·ªõi API Ollama (LLaVA)
                    try:
                        # user_input = """T·ª´ t·∫≠p d·ªØ li·ªáu "$(data_dv.csv)" Ph√¢n t√≠ch bi·ªÉu ƒë·ªì n√†y, m√¥ t·∫£ title c·ªßa bi·ªÉu ƒë·ªì, l√† d√≤ng ch·ªØ ph√≠a tr√™n b√™n tr√°i c·ªßa bi·ªÉu ƒë·ªì, ph√≠a sau k√≠ t·ª± 'üìä', m√¥ t·∫£ c√°c tr·ª•c c·ªßa bi·ªÉu ƒë·ªì, m√¥ t·∫£ c√°c ƒëi·ªÉm quan tr·ªçng c·ªßa bi·ªÉu ƒë·ªì, t·ª´ bi·ªÉu ƒë·ªì ƒë√≥ r√∫t ra m√¥ t·∫£ xu h∆∞·ªõng c·ªßa bi·ªÉu ƒë·ªì."""
                        chart_analysis_input = """B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu v√† tr·ª±c quan h√≥a, c√≥ k·ªπ nƒÉng ƒë·ªçc hi·ªÉu bi·ªÉu ƒë·ªì chuy√™n s√¢u. D·ª±a tr√™n bi·ªÉu ƒë·ªì c≈©ng nh∆∞ t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p, h√£y vi·∫øt m·ªôt b√°o c√°o ph√¢n t√≠ch chi ti·∫øt, r√µ r√†ng v√† m·∫°ch l·∫°c. B√°o c√°o c·∫ßn bao g·ªìm c√°c ph·∫ßn sau:
                                                T·ªïng quan: M√¥ t·∫£ lo·∫°i bi·ªÉu ƒë·ªì, m·ª•c ƒë√≠ch v√† √Ω nghƒ©a t·ªïng qu√°t. X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ ch√≠nh v√† ph·∫°m vi d·ªØ li·ªáu.
                                                Xu h∆∞·ªõng ch√≠nh: Ph√¢n t√≠ch c√°c xu h∆∞·ªõng n·ªïi b·∫≠t, s·ª± thay ƒë·ªïi ƒë√°ng ch√∫ √Ω v√† m·ªëi quan h·ªá gi·ªØa c√°c y·∫øu t·ªë trong bi·ªÉu ƒë·ªì.
                                                Chi ti·∫øt ƒë·∫∑c tr∆∞ng: L√†m r√µ c√°c ƒëi·ªÉm d·ªØ li·ªáu quan tr·ªçng, gi√° tr·ªã cao nh·∫•t, th·∫•p nh·∫•t, v√† c√°c ngo·∫°i l·ªá.
                                                Ph√°t hi·ªán ·∫©n: Nh·∫≠n di·ªán c√°c xu h∆∞·ªõng ho·∫∑c m·∫´u d·ªØ li·ªáu tinh t·∫ø m√† ng∆∞·ªùi xem th√¥ng th∆∞·ªùng c√≥ th·ªÉ b·ªè qua.
                                                K·∫øt lu·∫≠n: T√≥m t·∫Øt l·∫°i c√°c ph√°t hi·ªán quan tr·ªçng, ƒë∆∞a ra nh·∫≠n ƒë·ªãnh t·ªïng th·ªÉ v√† √Ω nghƒ©a t·ª´ bi·ªÉu ƒë·ªì.
                                                S·ª≠ d·ª•ng ng√¥n ng·ªØ chuy√™n nghi·ªáp, ch√≠nh x√°c, c√≥ d·∫´n ch·ª©ng s·ªë li·ªáu c·ª• th·ªÉ t·ª´ bi·ªÉu ƒë·ªì. H√£y ƒë·∫£m b·∫£o ph√¢n t√≠ch to√†n di·ªán, kh√¥ng b·ªè s√≥t th√¥ng tin quan tr·ªçng n√†o v√† r√∫t ra ƒë∆∞·ª£c nh·ªØng k·∫øt lu·∫≠n s√¢u s·∫Øc."""
                        # # Duy·ªát qua t·∫•t c·∫£ c√°c c·ªôt v√† d·ªØ li·ªáu
                        # for col in data.columns:
                        #     user_input += f"{col}: {data[col].tolist()}\n"
                        result = client.chat.completions.create(
                            model="gpt-4o",
                            messages=[
                                {"role": "system", "content": modelfile},
                                {"role": "user", "content":[
                                    {
                                        "type": "text",
                                        "text": chart_analysis_input
                                    },
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64, {img_base64}"
                                        }
                                    }
                                ]}
                            ],
                            max_tokens=500
                        )
                        
                        # Save image temporarily
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp_file:
                            image.save(tmp_file, format="PNG")
                            tmp_file_path = tmp_file.name

                            # pil_image = PILImage.new('RGB', (200, 100), color='blue')  # Example image
                            # pil_image.save(tmp_file_path, format="PNG")     

                            f = open(tmp_file_path, 'rb')

                            #################################
                            response_text = result.choices[0].message.content
                            st.write(response_text)

                            content.append(Image(f, width=10*cm, height=6*cm))
                            content.append(Spacer(1, 0.5 * cm))

                            paragraphs = response_text.split('\n')
                            for para in paragraphs:
                                if para.strip():
                                    content.append(Paragraph(para.strip(), custom_style))
                                    content.append(Spacer(1, 0.2 * cm))
                        ##################################


                        # c.drawImage(tmp_file_path, x_position, y_position - 200, width=450 ,height=200)
                        # # st.write(translator_ollava.translate(result['response']))

                        # # Gi·∫£m y_position sau khi th√™m ·∫£nh
                        # y_position -= 220

                        # # response_text = translator_ollava.translate(result['response'])
                        # response_text = result.choices[0].message.content
                        # st.write(response_text)
                        # wrapped_text = textwrap.wrap(response_text, width=80)

                        # for line in wrapped_text:
                        #     if y_position < 100:  # N·∫øu h·∫øt trang
                        #         c.showPage()
                        #         text_object = c.beginText(x_position, 750)
                        #         text_object.setFont("BeVietNamPro", 12)
                        #         y_position = 750

                        #     text_object.setTextOrigin(x_position, y_position)
                        #     text_object.textLine(line)
                        #     y_position -= 15  # Gi·∫£m y_position cho m·ªói d√≤ng

                        # c.drawText(text_object)

                            os.remove(tmp_file_path)
                            st.success("Analysis added to the PDF!")
                        # elif response.status_code == 403:
                        #     st.error("üö´ Forbidden: Check if the API endpoint requires authentication or IP whitelisting.")
                        # elif response.status_code == 404:
                        #     st.error("üîç API endpoint not found. Verify the URL.")
                        # else:
                        #     st.error(f"‚ö†Ô∏è Unexpected Error: {response.status_code}, {response.text}")
                        ####################################

                        # res = ollama.generate(model="data_science_assistant", prompt=user_input, images=[img_base64])

                        # st.write("Chatbot")
                        # st.write(res["response"])
                    except Exception as e:
                        st.error(f"L·ªói x·ª≠ l√Ω h√¨nh ·∫£nh: {e}")

            pdf.build(content)
            pdf_buffer.seek(0)

            st.write("Done")

            # Provide Download Button
            st.download_button(
                label="Download PDF",
                data=pdf_buffer,
                file_name="output.pdf",
                mime="application/pdf"
            )

# export_folder = os.path.join(os.getcwd(), "exports")
# sdf = SmartDataframe(data, config={"save_charts": True, "save_charts_path": export_folder, "verbose": True, "response_parser": StreamlitResponse, "custom_whitelisted_dependencies": ["to_numeric"]})
# with st.container():
#     # File uploader widget to upload a CSV file
#     config_file = st.file_uploader("Upload your config file", type=["json"])

#     images = []

#     if 'Send_button' not in st.session_state:
#         st.session_state.send_button = False
    
#     if st.button("Send"):
#         st.session_state.send_button = True

#     if st.session_state.send_button and config_file is not None:
#         # Open and read the JSON file
#         data = json.load(config_file)

#         report_name = data["Report Name"]
#         reporter_name = data["Reporter Name"]
#         graph_lists_name = data['Graphs']
#         colors = data["Colors"]

#         # Clear export folder before generating images
#         for file in os.listdir(export_folder):
#             file_path = os.path.join(export_folder, file)
#             if os.path.isfile(file_path) and file.lower().endswith(('.png', '.jpg', '.jpeg')):
#                 os.remove(file_path)

#         for index, graph in enumerate(graph_lists_name):
#             translated_graph_name = translator.translate(graph)

#             # translated_input = "Draw " + translated_graph_name + "with matplotlib and seaborn"
#             translated_input = "Plot " + translated_graph_name

#             response = sdf.chat(translated_input)

#             # Check if the response contains an image path
#             if isinstance(response, str) and os.path.isfile(response):  # If it's an image path
#                 image = Image.open(response)
#                 st.image(image)
#             else:
#                 # If the response isn't an image path, handle the output as text or other content
#                 st.write(response)

#             image_files = [f for f in os.listdir(export_folder) if f.endswith(('.png', '.jpg', '.jpeg'))]
#             st.write(image_files)

#             if image_files:
#                 image_path = os.path.join(export_folder, image_files[0])
#                 st.Image(image_path)
#                 images.append(Image.open(image_path))

        
#         for image in images:
#             st.Image(image)

#         st.session_state.send_button = False
