import streamlit as st
import pandas as pd
import plotly.express as px
import os
from PIL import Image as PILImage
import base64
import io
from io import BytesIO
import tempfile
from translate import Translator
from pandasai import SmartDataframe
from pandasai.responses.streamlit_response import StreamlitResponse
from pandasai.engine import set_pd_engine
from reportlab.lib.pagesizes import letter
from reportlab.pdfgen import canvas
from reportlab.pdfbase.ttfonts import TTFont
from reportlab.pdfbase import pdfmetrics
from openai import OpenAI

from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, Image
from reportlab.lib.units import cm

set_pd_engine("pandas")

# OpenAI API Key

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

# ƒêƒÉng k√Ω font Be VietNam Pro
pdfmetrics.registerFont(TTFont('BeVietNamPro', r'Be_Vietnam_Pro/BeVietnamPro-Light.ttf'))

export_folder = os.path.join(os.getcwd(), "exports")

# Load data
file_path = 'data_dv.csv'  # Replace with your uploaded file path
data = pd.read_csv(file_path)

# Page configuration
st.set_page_config(page_title="ChatBot", layout="wide")

# T√πy ch·ªânh CSS ƒë·ªÉ ƒë·∫©y Markdown s√°t tr√™n c√πng
st.markdown(
    """
    <style>
        .block-container {
            padding-top: 2rem; /* Lo·∫°i b·ªè kho·∫£ng c√°ch ph√≠a tr√™n */
        }
        h1 {
            text-align: center;
            margin-top: 0;
            padding-top: 0;
        }
    </style>
    """,
    unsafe_allow_html=True
)
st.markdown("<h3 style='text-align: center;'>ChatBot</h3>", unsafe_allow_html=True)

####################################################
st.markdown("![Alt Text](https://media.giphy.com/media/G56u3vJFPIevIfVnEK/giphy.gif)")
####################################################


translator = Translator(to_lang="en", from_lang="vi")

with st.container():
    col1, col2 = st.columns(2)
    with col1.container(border=True):
        os.environ["PANDASAI_API_KEY"] = "$2a$10$GEsfXrwFuOWndHnBgXcSkecd3RlY3ffzDyDk19gXMRue4Dr.oqz4m"

        sdf = SmartDataframe(data, config={"save_charts": True, "save_charts_path": export_folder, "verbose": True, "response_parser": StreamlitResponse, "custom_whitelisted_dependencies": ["to_numeric"]})

        user_input = st.chat_input("Ask me:")

        if user_input:
            with st.container(border=True):
                with st.chat_message("assistant"):

                    translated_text = translator.translate(user_input)

                    response = sdf.chat(translated_text)

                    if isinstance(response, pd.DataFrame):
                        # Display the DataFrame directly
                        st.write(f"Chatbot:")
                        st.write(response)
                    else:
                        # If the response is a string (e.g., some text or CSV), handle it accordingly
                        # For example, if it's a CSV-like string:
                        st.write(f"Chatbot: {response}")

    with col2.container(border=True):
        
        modelfile = f"""B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu v√† bi·ªÉu ƒë·ªì v·ªõi ch·ªß ƒë·ªÅ Tai n·∫°n giao th√¥ng ·ªü Vi·ªát Nam, b·∫°n c√≥ th·ªÉ s·ª≠ d·ª•ng th√¥ng tin dataset ·ªü ƒë√¢y {data}"""

        # User input
        img_file_buffer = st.file_uploader("Upload an image", type=["png", "jpg", "jpeg"], accept_multiple_files=True)
        user_input = st.chat_input("Ask me ><:")

        if user_input:
            st.write("Input")

            introduce_dataset_input = """H√£y vi·∫øt m·ªôt b·∫£n b√°o c√°o gi·ªõi thi·ªáu s∆° l∆∞·ª£c v·ªÅ t·∫≠p d·ªØ li·ªáu tai n·∫°n giao th√¥ng ·ªü Vi·ªát Nam, m√¥ t·∫£ c√°c thu·ªôc t√≠nh c≈©ng nh∆∞ s·ª≠ d·ª•ng c√°c ph√©p to√°n th·ªëng k√™ ƒë∆°n gi·∫£n cho t·∫≠p d·ªØ li·ªáu"""

            result = client.chat.completions.create(
                            model="gpt-4",
                            messages=[
                                {"role": "system", "content": modelfile},
                                {"role": "user", "content": introduce_dataset_input}
                            ],
                            max_tokens=500
                        )
            response_text = result.choices[0].message.content
            st.write(response_text)


            ##################################
            # T·∫°o file PDF
            pdf_buffer = io.BytesIO()

            pdf = SimpleDocTemplate(pdf_buffer, pagesize=A4)
            styles = getSampleStyleSheet()
            
            # T√πy ch·ªânh c√°c style
            title_style = ParagraphStyle(
                'TitleStyle', fontName='BeVietNamPro', fontSize=18, alignment=1, spaceAfter=12
            )
            body_style = ParagraphStyle(
                'BodyStyle', fontName='BeVietNamPro', fontSize=12, leading=14, spaceAfter=10
            )
            custom_style = ParagraphStyle(
                'CustomStyle', parent=body_style, alignment=0, spaceAfter=10
            )
            
            # N·ªôi dung PDF
            content = []
            content.append(Paragraph('B√°o C√°o Tai N·∫°n Giao Th√¥ng', title_style))
            content.append(Spacer(1, 0.5 * cm))
            
            # L·∫∑p 3 l·∫ßn ƒë·ªÉ ch√®n vƒÉn b·∫£n v√† ·∫£nh
            paragraphs = response_text.split('\n')
            for para in paragraphs:
                if para.strip():
                    content.append(Paragraph(para.strip(), custom_style))
                    content.append(Spacer(1, 0.2 * cm))
            
            #################################

            st.success("Introduction added to the PDF!")


        # Hi·ªÉn th·ªã h√¨nh ·∫£nh n·∫øu ng∆∞·ªùi d√πng t·∫£i l√™n
            for image in img_file_buffer:
                if image:
                    image = PILImage.open(image)
                    # st.image(image, caption="·∫¢nh ƒë√£ t·∫£i l√™n", width=500)
                    # image = image.resize((512, 200))
                    # image = image.convert("L")

                    buffered = io.BytesIO()
                    image.save(buffered, format="PNG")
                    img_base64 = base64.b64encode(buffered.getvalue()).decode('utf-8')

                    # X·ª≠ l√Ω h√¨nh ·∫£nh v·ªõi API Ollama (LLaVA)
                    try:
                        # user_input = """T·ª´ t·∫≠p d·ªØ li·ªáu "$(data_dv.csv)" Ph√¢n t√≠ch bi·ªÉu ƒë·ªì n√†y, m√¥ t·∫£ title c·ªßa bi·ªÉu ƒë·ªì, l√† d√≤ng ch·ªØ ph√≠a tr√™n b√™n tr√°i c·ªßa bi·ªÉu ƒë·ªì, ph√≠a sau k√≠ t·ª± 'üìä', m√¥ t·∫£ c√°c tr·ª•c c·ªßa bi·ªÉu ƒë·ªì, m√¥ t·∫£ c√°c ƒëi·ªÉm quan tr·ªçng c·ªßa bi·ªÉu ƒë·ªì, t·ª´ bi·ªÉu ƒë·ªì ƒë√≥ r√∫t ra m√¥ t·∫£ xu h∆∞·ªõng c·ªßa bi·ªÉu ƒë·ªì."""
                        chart_analysis_input = """B·∫°n l√† m·ªôt chuy√™n gia ph√¢n t√≠ch d·ªØ li·ªáu v√† tr·ª±c quan h√≥a, c√≥ k·ªπ nƒÉng ƒë·ªçc hi·ªÉu bi·ªÉu ƒë·ªì chuy√™n s√¢u. D·ª±a tr√™n bi·ªÉu ƒë·ªì c≈©ng nh∆∞ t·∫≠p d·ªØ li·ªáu ƒë∆∞·ª£c cung c·∫•p, h√£y vi·∫øt m·ªôt b√°o c√°o ph√¢n t√≠ch chi ti·∫øt, r√µ r√†ng v√† m·∫°ch l·∫°c. B√°o c√°o c·∫ßn bao g·ªìm c√°c ph·∫ßn sau:
                                                T·ªïng quan: M√¥ t·∫£ lo·∫°i bi·ªÉu ƒë·ªì, m·ª•c ƒë√≠ch v√† √Ω nghƒ©a t·ªïng qu√°t. X√°c ƒë·ªãnh ch·ªß ƒë·ªÅ ch√≠nh v√† ph·∫°m vi d·ªØ li·ªáu.
                                                Xu h∆∞·ªõng ch√≠nh: Ph√¢n t√≠ch c√°c xu h∆∞·ªõng n·ªïi b·∫≠t, s·ª± thay ƒë·ªïi ƒë√°ng ch√∫ √Ω v√† m·ªëi quan h·ªá gi·ªØa c√°c y·∫øu t·ªë trong bi·ªÉu ƒë·ªì.
                                                Chi ti·∫øt ƒë·∫∑c tr∆∞ng: L√†m r√µ c√°c ƒëi·ªÉm d·ªØ li·ªáu quan tr·ªçng, gi√° tr·ªã cao nh·∫•t, th·∫•p nh·∫•t, v√† c√°c ngo·∫°i l·ªá.
                                                Ph√°t hi·ªán ·∫©n: Nh·∫≠n di·ªán c√°c xu h∆∞·ªõng ho·∫∑c m·∫´u d·ªØ li·ªáu tinh t·∫ø m√† ng∆∞·ªùi xem th√¥ng th∆∞·ªùng c√≥ th·ªÉ b·ªè qua.
                                                K·∫øt lu·∫≠n: T√≥m t·∫Øt l·∫°i c√°c ph√°t hi·ªán quan tr·ªçng, ƒë∆∞a ra nh·∫≠n ƒë·ªãnh t·ªïng th·ªÉ v√† √Ω nghƒ©a t·ª´ bi·ªÉu ƒë·ªì.
                                                S·ª≠ d·ª•ng ng√¥n ng·ªØ chuy√™n nghi·ªáp, ch√≠nh x√°c, c√≥ d·∫´n ch·ª©ng s·ªë li·ªáu c·ª• th·ªÉ t·ª´ bi·ªÉu ƒë·ªì. H√£y ƒë·∫£m b·∫£o ph√¢n t√≠ch to√†n di·ªán, kh√¥ng b·ªè s√≥t th√¥ng tin quan tr·ªçng n√†o v√† r√∫t ra ƒë∆∞·ª£c nh·ªØng k·∫øt lu·∫≠n s√¢u s·∫Øc."""
                        # # Duy·ªát qua t·∫•t c·∫£ c√°c c·ªôt v√† d·ªØ li·ªáu
                        # for col in data.columns:
                        #     user_input += f"{col}: {data[col].tolist()}\n"
                        result = client.chat.completions.create(
                            model="gpt-4o",
                            messages=[
                                {"role": "system", "content": modelfile},
                                {"role": "user", "content":[
                                    {
                                        "type": "text",
                                        "text": chart_analysis_input
                                    },
                                    {
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/png;base64, {img_base64}"
                                        }
                                    }
                                ]}
                            ],
                            max_tokens=500
                        )
                        
                        # Save image temporarily
                        with tempfile.NamedTemporaryFile(delete=False, suffix=".png") as tmp_file:
                            image.save(tmp_file, format="PNG")
                            tmp_file_path = tmp_file.name

                            # pil_image = PILImage.new('RGB', (200, 100), color='blue')  # Example image
                            # pil_image.save(tmp_file_path, format="PNG")     

                            f = open(tmp_file_path, 'rb')

                            #################################
                            response_text = result.choices[0].message.content
                            st.write(response_text)

                            content.append(Image(f, width=10*cm, height=6*cm))
                            content.append(Spacer(1, 0.5 * cm))

                            paragraphs = response_text.split('\n')
                            for para in paragraphs:
                                if para.strip():
                                    content.append(Paragraph(para.strip(), custom_style))
                                    content.append(Spacer(1, 0.2 * cm))
                        ##################################

                        # c.drawText(text_object)

                            os.remove(tmp_file_path)
                            st.success("Analysis added to the PDF!")
                    except Exception as e:
                        st.error(f"L·ªói x·ª≠ l√Ω h√¨nh ·∫£nh: {e}")

            pdf.build(content)
            pdf_buffer.seek(0)

            st.write("Done")

            # Provide Download Button
            st.download_button(
                label="Download PDF",
                data=pdf_buffer,
                file_name="output.pdf",
                mime="application/pdf"
            )
